## Introduction
* Hello there ðŸ‘‹, Iâ€™m Tonny-Bright. I work as a Lead Operations Engineer at Dreamoval, a Freelancer and a data science enthusiast. Python is my language of choice for most things. I'm however familiar with other tools and processes in the software development life cycle.

* Iâ€™m a certified AWS Solutions Architect Associate and have worked as a Cloud Engineer for three and half years. In those years, I have worked mainly with AWS services ranging from EC2, VPC, ECS, Aurora, Data Migration Service, Schema Conversion Tool, AWS Glue, Athena, RedShift, Dynamodb, Lambda, S3, etc. 

* Other tools and services apart from AWS include Datadog, Metabase for Business Intelligence dashboarding and analysis, Elasticsearch, Kibana, Apache kafka, Microservices Architecture, MongoDB, MySQL, Redis, Django, Django Rest Framework, Celery, Javascript, Terraform, Jenkins, Docker, Ansible etc. 

* Iâ€™m looking to collaborate on anything relating to Data; backend software engineering, cloud engineering (AWS), data pipelines, data warehouses, data lakes, delta lake, data analysis, machine learning.

---

## Projects
* [LawSMS](https://isms.lawsms.com/). A [mobile](https://play.google.com/store/apps/details?id=com.lawsms.app) and [web](https://isms.lawsms.com/) application to deliver legal content through SMS subscriptions. Using Django and Django Rest Framework for APIs to be consumed by the mobile and web applications.

* [ECS Infrastructure](https://github.com/TMCreme/terraform-airflow-ecs) using Terraform. Provisioning an ECS Cluster with Terraform including VPC, subnets, Internet gateway, Security groups, Load balancer, etc. 

* [Data Pipeline](https://github.com/TMCreme/dbt_airflow_project) using Apache Airflow and DBT deployed on AWS ECS. The aim was simulate a real world scenario of data ingestion, transformation, persisting and analysis. Airflow handles the orchestration hence the ingestion was implemented in custom python code with Airflow operators and tasks. With the file sensors in Airflow, this can be extended for streaming for data files. Transformations are handled in Data Build Tool (DBT) and stored in PostgreSQL. By use of a Jenkinsfile, the project is build successfully for deployment and stored on Dockerhub.

* [Image Processing](https://github.com/TMCreme/drf-image-uploader) with django rest framework, Celery and S3. Image is uploaded and stored on AWS S3 bucket. A background process in Celery generates various sizes of the image and saves in a the S3 bucket alongside the original image. Also contains an API to return an AWS S3 presigned URL to the image for a specified period of time. 

* [Data Streaming](https://github.com/TMCreme/twitter-sentiments-pyspark) using PySpark, Apache Kafka and Tweepy. The streaming projects aims to simulate realtime data streaming and analysis on the fly. The Tweepy package allows us to access tweets based on specific parameters. The tweets are streamed onto a kafka topic, on which by the help of PySpark Structured Streaming, a listener is available for any data arriving. The data is aggregated, transformed and a plot generated for viewing. 

* Other projects including APIs in django are available in my repository.  

---

## Certifications
<p align="center">
<a href="https://www.credly.com/badges/5eee5d85-eed4-4158-a372-fa86504ed74d/public_url"><img width="48%" height="50%" src="https://images.credly.com/size/200x200/images/0e284c3f-5164-4b21-8660-0d84737941bc/image.png"></a>
</p>


---

## Positions
* ### Lead Operations Engineer, Dreamoval Limited (May 2021 - September 2022)

* ### Technical Support Engineer, Dreamoval Limited (June 2019 to April 2021)


* ### Freelancer(Software and Data Engineering), (October 2017 - present)

---

<p align="center">
<img width="48%" height="50%" src="https://github-readme-stats.vercel.app/api/top-langs/?username=TMCreme&layout=compact&theme=dracula">
</p>

---

<h1 align="center"> ðŸ”§ Technologies & Tools </h1>

![](https://img.shields.io/badge/OS-Linux-informational?style=flat&logo=linux&logoColor=white&color=3498DB)
![](https://img.shields.io/badge/Code-Python-informational?style=flat&logo=python&logoColor=white&color=9B59B6)
![](https://img.shields.io/badge/Code-JavaScript-informational?style=flat&logo=javascript&logoColor=white&color=9B59B6)
![](https://img.shields.io/badge/Code-Fastapi-informational?style=flat&logo=fastapi&logoColor=white&color=9B59B6)
![](https://img.shields.io/badge/Code-R-informational?style=flat&logo=r&logoColor=white&color=9B59B6)
![](https://img.shields.io/badge/Code-Django-informational?style=flat&logo=django&logoColor=white&color=9B59B6)
![](https://img.shields.io/badge/Code-HTML-informational?style=flat&logo=html5&logoColor=white&color=9B59B6)
![](https://img.shields.io/badge/Tools-AWS-informational?style=flat&logo=amazon&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Docker-informational?style=flat&logo=docker&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Mysql-informational?style=flat&logo=mysql&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-MongoDB-informational?style=flat&logo=mongodb&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-PostgreSQL-informational?style=flat&logo=postgresql&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Elasticsearch-informational?style=flat&logo=elasticsearch&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Kibana-informational?style=flat&logo=kibana&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Redis-informational?style=flat&logo=Redis&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Terraform-informational?style=flat&logo=terraform&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Jenkins-informational?style=flat&logo=jenkins&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Ansible-informational?style=flat&logo=ansible&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Datadog-informational?style=flat&logo=datadog&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Airflow-informational?style=flat&logo=apacheairflow&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-PySpark-informational?style=flat&logo=apachespark&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Kafka-informational?style=flat&logo=apachekafka&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-DBT-informational?style=flat&logo=dbt&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Nginx-informational?style=flat&logo=nginx&logoColor=white&color=1ABC9C)
![](https://img.shields.io/badge/Tools-Celery-informational?style=flat&logo=celery&logoColor=white&color=1ABC9C)


---

## Github Stats

<a><img align="center" src="https://github-readme-stats.vercel.app/api?username=TMCreme&show_icons=true&theme=dracula" /></a>

<a><img align="center" src="https://github-readme-streak-stats.herokuapp.com/?user=TMCreme&theme=dracula"/></a>

---

## Contact
- ðŸ“« Reach me at [email](mailto:tonnybright35@gmail.com), [Twitter](https://twitter.com/BrightTonny), [Linkedin](https://www.linkedin.com/in/tonny-bright-sogli-245566a9/) 



