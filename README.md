## Introduction
* Hello there ðŸ‘‹, Iâ€™m Tonny-Bright. I work as a Lead Operations Engineer at Dreamoval, a Freelancer and a data science enthusiast. Python is my language of choice for most things. I'm however familiar with other tools and processes in the software development life cycle.

* Iâ€™m a certified AWS Solutions Architect Associate and have worked as a Cloud Engineer for three and half years. In those years, I have worked mainly with AWS services ranging from EC2, VPC, ECS, Aurora, Data Migration Service, Schema Conversion Tool, AWS Glue, Athena, RedShift, Dynamodb, Lambda, S3, etc. 

* Other tools and services apart from AWS include Datadog, Metabase for Business Intelligence dashboarding and analysis, Elasticsearch, Kibana, Apache kafka, Microservices Architecture, MongoDB, MySQL, Redis, Django, Django Rest Framework, Celery, Javascript, Terraform, Jenkins, Docker, Ansible etc. 

* Iâ€™m looking to collaborate on anything relating to Data; backend software engineering, cloud engineering (AWS), data pipelines, data warehouses, data lakes, delta lake, data analysis, machine learning.

## Projects
* [Data Pipeline](https://github.com/TMCreme/dbt_airflow_project) using Apache Airflow and DBT deployed on AWS ECS. The aim was simulate a real world scenario of data ingestion, transformation, persisting and analysis. Airflow handles the orchestration hence the ingestion was implemented in custom python code with Airflow operators and tasks. With the file sensors in Airflow, this can be extended for streaming for data files. Transformations are handled in Data Build Tool (DBT) and stored in PostgreSQL. By use of a Jenkinsfile, the project is build successfully for deployment and stored on Dockerhub.

* [ECS Infrastructure](https://github.com/TMCreme/terraform-airflow-ecs) using Terraform. Provisioning an ECS Cluster with Terraform including VPC, subnets, Internet gateway, Security groups, Load balancer, etc. 

* [Image Processing](https://github.com/TMCreme/drf-image-uploader) with django rest framework, Celery and S3. Image is uploaded and stored on AWS S3 bucket. A background process in Celery generates various sizes of the image and saves in a the S3 bucket alongside the original image. Also contains an API to return an AWS S3 presigned URL to the image for a specified period of time. 

* [Data Streaming](https://github.com/TMCreme/twitter-sentiments-pyspark) using PySpark, Apache Kafka and Tweepy. The streaming projects aims to simulate realtime data streaming and analysis on the fly. The Tweepy package allows us to access tweets based on specific parameters. The tweets are streamed onto a kafka topic, on which by the help of PySpark Structured Streaming, a listener is available for any data arriving. The data is aggregated, transformed and a plot generated for viewing. 

* [LawSMS](https://isms.lawsms.com/). A [mobile](https://play.google.com/store/apps/details?id=com.lawsms.app) and [web](https://isms.lawsms.com/) application to deliver legal content through SMS subscriptions. Using Django and Django Rest Framework for APIs to be consumed by the mobile and web applications

* Other projects including APIs in django are available in my repository.  

## Certifications
* [AWS Certified Solutions Architect](https://www.credly.com/badges/5eee5d85-eed4-4158-a372-fa86504ed74d/public_url)

## Positions
* ### Lead Operations Engineer, Dreamoval Limited (May 2021 - September 2022)
    - Lead, Service Operations Centre Engineering Unit 
    - Led a successful planning and execution of robust data management that improved the performance of the firmâ€™s software applications and ensured quality data.
    - Developed an ETL pipeline for loading archived data for querying using AWS Glue, Athena, and AWS S3.
    - Wrote native MongoDB and SQL queries that generate business intelligence data periodically. 
    - Automated reconciliation activities for the reconciliation and settlement team using Python scripts. 
    - Periodic reporting by preparing Business Intelligence dashboards for management to measure the performance of products. 
    - Analyzing data from databases and logs to inform the Product team on which features to prioritize, and the sales and marketing team on the type of customers to target. 
    - Led the successful API integration of 395 businesses (including Fintech Companies and Banks) which resulted in a 40% increase in total transaction volume 
    - Successfully managed enterprise clientsâ€™ engagement that improved Net Promoter Score by 20% and eliminated unnecessary escalations. 
    - Led cross-functional team engagements by explaining technical issues to non-technical and technical teams including Products, Enterprise and Consulting Services, Security and Compliance, Engineering, and Solution Delivery. 
    - Led the timely restoration of failing critical services, applications, and infrastructure in a 10-member team(remote and in-person) to meet SLAs and SLOs as regards security, availability, and reliability.
    - Automated performance reports to the regulator as part of compliance requirements using Python scripts.
    - Serves as the data custodian for the organization in order to have a consolidated form of reporting on business performance
    - Implemented Automated testing into the CI/CD pipeline in order to prevent regression on deployments. 
    - Wrote maintenance and automation scripts to facilitate the deployment of enterprise applications.
    - Debugging and finding the root cause of issues to be reported to the development team 


* ### Technical Support Engineer, Dreamoval Limited (June 2019 to April 2021)
    - Automated data generation for billing Enterprise Clients to be sent to the Finance team periodically. 
    - Migrated a standalone MongoDB to cluster MongoDB to improve performance and reliability. 
    - Migrated microservice applications with MySQL database from Ubuntu to Enterprise RedHat Linux to meet the clientsâ€™ architecture requirements.
    - Reduced the error rate on production systems by 20% by analyzing data for error patterns and reporting to the development team for optimization. 
    - Determined the profitability of software products by analyzing the conversion rate and active usersâ€™ performance. 
    - Led the Implementation of the incident management process including identifying the issue, declaring, labeling incidents with appropriate severity, coordinating, escalations, communications, and restoration of service.  
    - Deployment and maintenance of applications (Cloud and on-premise) 
    - Successfully managed enterprise clientsâ€™ engagement that improved Net Promoter Score by 10% and eliminated unnecessary escalations.  
    - Scripting for maintenance and automation with Python and Ansible  
    - Ansible scripts for automating the deployment of applications to be integrated into the CI/CD Pipeline 
    - Provided On-site and Remote support for Enterprise clients


* ### Freelancer(Software and Data Engineering), (October 2017 - present)

## Tech Stack
### Languages 
* Python - Senior 
* JavaScript - Mid-Level 
* R - Mid-Level
* HTML5 

### Frameworks
* Django - Senior 
* FastAPi  Mid-Level
* Nodejs - Beginner

### Databases
* MongoDB
* MySQL 
* PostgreSQL 
* Snowflake 
* Redis
* Elasticsearch 

### CI/CD
* Jenkins
* TeamCity 

### Cloud 
* AWS - Senior
* Microsoft Azure 
* Heroku 

### Containers 
* Docker
* Docker Compose

### Automation and Infrastructure as Code
* Ansible 
* Terraform 

### Monitoring
* Datadog
* Kibana

### Others 
* Numpy
* Pandas
* Pytorch
* Airflow 
* DBT 
* PySpark
* Apache Kafka
* JIRA
* Nginx 
* Celery 

## Contact
- ðŸ“« Reach me at mailto:tonnybright35@gmail.com via email, [Twitter](https://twitter.com/BrightTonny), [Linkedin](https://www.linkedin.com/in/tonny-bright-sogli-245566a9/) 



